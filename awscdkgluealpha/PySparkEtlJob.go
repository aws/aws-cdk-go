package awscdkgluealpha

import (
	_init_ "github.com/aws/aws-cdk-go/awscdkgluealpha/v2/jsii"
	_jsii_ "github.com/aws/jsii-runtime-go/runtime"

	"github.com/aws/aws-cdk-go/awscdk/v2"
	"github.com/aws/aws-cdk-go/awscdk/v2/awscloudwatch"
	"github.com/aws/aws-cdk-go/awscdk/v2/awsevents"
	"github.com/aws/aws-cdk-go/awscdk/v2/awsiam"
	"github.com/aws/constructs-go/constructs/v10"
)

// PySpark ETL Jobs class.
//
// ETL jobs support pySpark and Scala languages, for which there are separate
// but similar constructors. ETL jobs default to the G2 worker type, but you
// can override this default with other supported worker type values
// (G1, G2, G4 and G8). ETL jobs defaults to Glue version 4.0, which you can
// override to 3.0. The following ETL features are enabled by default:
// —enable-metrics, —enable-spark-ui, —enable-continuous-cloudwatch-log.
// You can find more details about version, worker type and other features
// in Glue's public documentation.
//
// Example:
//   import cdk "github.com/aws/aws-cdk-go/awscdk"
//   import iam "github.com/aws/aws-cdk-go/awscdk"
//   var stack stack
//   var role iRole
//   var script code
//
//   glue.NewPySparkEtlJob(stack, jsii.String("PySparkETLJob"), &PySparkEtlJobProps{
//   	Role: Role,
//   	Script: Script,
//   	JobName: jsii.String("PySparkETLJob"),
//   	JobRunQueuingEnabled: jsii.Boolean(true),
//   })
//
// Experimental.
type PySparkEtlJob interface {
	SparkJob
	// The environment this resource belongs to.
	//
	// For resources that are created and managed by the CDK
	// (generally, those created by creating new class instances like Role, Bucket, etc.),
	// this is always the same as the environment of the stack they belong to;
	// however, for imported resources
	// (those obtained from static methods like fromRoleArn, fromBucketName, etc.),
	// that might be different than the stack they were imported into.
	// Experimental.
	Env() *awscdk.ResourceEnvironment
	// The principal to grant permissions to.
	// Experimental.
	GrantPrincipal() awsiam.IPrincipal
	// The ARN of the job.
	// Experimental.
	JobArn() *string
	// The name of the job.
	// Experimental.
	JobName() *string
	// The tree node.
	// Experimental.
	Node() constructs.Node
	// Returns a string-encoded token that resolves to the physical name that should be passed to the CloudFormation resource.
	//
	// This value will resolve to one of the following:
	// - a concrete value (e.g. `"my-awesome-bucket"`)
	// - `undefined`, when a name should be generated by CloudFormation
	// - a concrete name generated automatically during synthesis, in
	//   cross-environment scenarios.
	// Experimental.
	PhysicalName() *string
	// The IAM role Glue assumes to run this job.
	// Experimental.
	Role() awsiam.IRole
	// The Spark UI logs location if Spark UI monitoring and debugging is enabled.
	// See: https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html
	//
	// Experimental.
	SparkUILoggingLocation() *SparkUILoggingLocation
	// The stack in which this resource is defined.
	// Experimental.
	Stack() awscdk.Stack
	// Apply the given removal policy to this resource.
	//
	// The Removal Policy controls what happens to this resource when it stops
	// being managed by CloudFormation, either because you've removed it from the
	// CDK application or because you've made a change that requires the resource
	// to be replaced.
	//
	// The resource can be deleted (`RemovalPolicy.DESTROY`), or left in your AWS
	// account for data recovery and cleanup later (`RemovalPolicy.RETAIN`).
	// Experimental.
	ApplyRemovalPolicy(policy awscdk.RemovalPolicy)
	// Returns the job arn.
	// Experimental.
	BuildJobArn(scope constructs.Construct, jobName *string) *string
	// Check no usage of reserved arguments.
	// See: https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html
	//
	// Experimental.
	CheckNoReservedArgs(defaultArguments *map[string]*string) *map[string]*string
	// Experimental.
	CodeS3ObjectUrl(code Code) *string
	// Experimental.
	GeneratePhysicalName() *string
	// Returns an environment-sensitive token that should be used for the resource's "ARN" attribute (e.g. `bucket.bucketArn`).
	//
	// Normally, this token will resolve to `arnAttr`, but if the resource is
	// referenced across environments, `arnComponents` will be used to synthesize
	// a concrete ARN with the resource's physical name. Make sure to reference
	// `this.physicalName` in `arnComponents`.
	// Experimental.
	GetResourceArnAttribute(arnAttr *string, arnComponents *awscdk.ArnComponents) *string
	// Returns an environment-sensitive token that should be used for the resource's "name" attribute (e.g. `bucket.bucketName`).
	//
	// Normally, this token will resolve to `nameAttr`, but if the resource is
	// referenced across environments, it will be resolved to `this.physicalName`,
	// which will be a concrete name.
	// Experimental.
	GetResourceNameAttribute(nameAttr *string) *string
	// Create a CloudWatch metric.
	// See: https://docs.aws.amazon.com/glue/latest/dg/monitoring-awsglue-with-cloudwatch-metrics.html
	//
	// Experimental.
	Metric(metricName *string, type_ MetricType, props *awscloudwatch.MetricOptions) awscloudwatch.Metric
	// Return a CloudWatch Metric indicating job failure.
	//
	// This metric is based on the Rule returned by no-args onFailure() call.
	// Experimental.
	MetricFailure(props *awscloudwatch.MetricOptions) awscloudwatch.Metric
	// Return a CloudWatch Metric indicating job success.
	//
	// This metric is based on the Rule returned by no-args onSuccess() call.
	// Experimental.
	MetricSuccess(props *awscloudwatch.MetricOptions) awscloudwatch.Metric
	// Return a CloudWatch Metric indicating job timeout.
	//
	// This metric is based on the Rule returned by no-args onTimeout() call.
	// Experimental.
	MetricTimeout(props *awscloudwatch.MetricOptions) awscloudwatch.Metric
	// Experimental.
	NonExecutableCommonArguments(props *SparkJobProps) *map[string]*string
	// Create a CloudWatch Event Rule for this Glue Job when it's in a given state.
	// See: https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/EventTypes.html#glue-event-types
	//
	// Experimental.
	OnEvent(id *string, options *awsevents.OnEventOptions) awsevents.Rule
	// Return a CloudWatch Event Rule matching FAILED state.
	// Experimental.
	OnFailure(id *string, options *awsevents.OnEventOptions) awsevents.Rule
	// Create a CloudWatch Event Rule for the transition into the input jobState.
	// Experimental.
	OnStateChange(id *string, jobState JobState, options *awsevents.OnEventOptions) awsevents.Rule
	// Create a CloudWatch Event Rule matching JobState.SUCCEEDED.
	// Experimental.
	OnSuccess(id *string, options *awsevents.OnEventOptions) awsevents.Rule
	// Return a CloudWatch Event Rule matching TIMEOUT state.
	// Experimental.
	OnTimeout(id *string, options *awsevents.OnEventOptions) awsevents.Rule
	// Setup Continuous Logging Properties.
	//
	// Returns: String containing the args for the continuous logging command.
	// Experimental.
	SetupContinuousLogging(role awsiam.IRole, props *ContinuousLoggingProps) interface{}
	// Set the arguments for extra {@link Code}-related properties.
	// Experimental.
	SetupExtraCodeArguments(args *map[string]*string, props *SparkExtraCodeProps)
	// Returns a string representation of this construct.
	// Experimental.
	ToString() *string
}

// The jsii proxy struct for PySparkEtlJob
type jsiiProxy_PySparkEtlJob struct {
	jsiiProxy_SparkJob
}

func (j *jsiiProxy_PySparkEtlJob) Env() *awscdk.ResourceEnvironment {
	var returns *awscdk.ResourceEnvironment
	_jsii_.Get(
		j,
		"env",
		&returns,
	)
	return returns
}

func (j *jsiiProxy_PySparkEtlJob) GrantPrincipal() awsiam.IPrincipal {
	var returns awsiam.IPrincipal
	_jsii_.Get(
		j,
		"grantPrincipal",
		&returns,
	)
	return returns
}

func (j *jsiiProxy_PySparkEtlJob) JobArn() *string {
	var returns *string
	_jsii_.Get(
		j,
		"jobArn",
		&returns,
	)
	return returns
}

func (j *jsiiProxy_PySparkEtlJob) JobName() *string {
	var returns *string
	_jsii_.Get(
		j,
		"jobName",
		&returns,
	)
	return returns
}

func (j *jsiiProxy_PySparkEtlJob) Node() constructs.Node {
	var returns constructs.Node
	_jsii_.Get(
		j,
		"node",
		&returns,
	)
	return returns
}

func (j *jsiiProxy_PySparkEtlJob) PhysicalName() *string {
	var returns *string
	_jsii_.Get(
		j,
		"physicalName",
		&returns,
	)
	return returns
}

func (j *jsiiProxy_PySparkEtlJob) Role() awsiam.IRole {
	var returns awsiam.IRole
	_jsii_.Get(
		j,
		"role",
		&returns,
	)
	return returns
}

func (j *jsiiProxy_PySparkEtlJob) SparkUILoggingLocation() *SparkUILoggingLocation {
	var returns *SparkUILoggingLocation
	_jsii_.Get(
		j,
		"sparkUILoggingLocation",
		&returns,
	)
	return returns
}

func (j *jsiiProxy_PySparkEtlJob) Stack() awscdk.Stack {
	var returns awscdk.Stack
	_jsii_.Get(
		j,
		"stack",
		&returns,
	)
	return returns
}


// PySparkEtlJob constructor.
// Experimental.
func NewPySparkEtlJob(scope constructs.Construct, id *string, props *PySparkEtlJobProps) PySparkEtlJob {
	_init_.Initialize()

	if err := validateNewPySparkEtlJobParameters(scope, id, props); err != nil {
		panic(err)
	}
	j := jsiiProxy_PySparkEtlJob{}

	_jsii_.Create(
		"@aws-cdk/aws-glue-alpha.PySparkEtlJob",
		[]interface{}{scope, id, props},
		&j,
	)

	return &j
}

// PySparkEtlJob constructor.
// Experimental.
func NewPySparkEtlJob_Override(p PySparkEtlJob, scope constructs.Construct, id *string, props *PySparkEtlJobProps) {
	_init_.Initialize()

	_jsii_.Create(
		"@aws-cdk/aws-glue-alpha.PySparkEtlJob",
		[]interface{}{scope, id, props},
		p,
	)
}

// Identifies an existing Glue Job from a subset of attributes that can be referenced from within another Stack or Construct.
// Experimental.
func PySparkEtlJob_FromJobAttributes(scope constructs.Construct, id *string, attrs *JobAttributes) IJob {
	_init_.Initialize()

	if err := validatePySparkEtlJob_FromJobAttributesParameters(scope, id, attrs); err != nil {
		panic(err)
	}
	var returns IJob

	_jsii_.StaticInvoke(
		"@aws-cdk/aws-glue-alpha.PySparkEtlJob",
		"fromJobAttributes",
		[]interface{}{scope, id, attrs},
		&returns,
	)

	return returns
}

// Checks if `x` is a construct.
//
// Use this method instead of `instanceof` to properly detect `Construct`
// instances, even when the construct library is symlinked.
//
// Explanation: in JavaScript, multiple copies of the `constructs` library on
// disk are seen as independent, completely different libraries. As a
// consequence, the class `Construct` in each copy of the `constructs` library
// is seen as a different class, and an instance of one class will not test as
// `instanceof` the other class. `npm install` will not create installations
// like this, but users may manually symlink construct libraries together or
// use a monorepo tool: in those cases, multiple copies of the `constructs`
// library can be accidentally installed, and `instanceof` will behave
// unpredictably. It is safest to avoid using `instanceof`, and using
// this type-testing method instead.
//
// Returns: true if `x` is an object created from a class which extends `Construct`.
// Experimental.
func PySparkEtlJob_IsConstruct(x interface{}) *bool {
	_init_.Initialize()

	if err := validatePySparkEtlJob_IsConstructParameters(x); err != nil {
		panic(err)
	}
	var returns *bool

	_jsii_.StaticInvoke(
		"@aws-cdk/aws-glue-alpha.PySparkEtlJob",
		"isConstruct",
		[]interface{}{x},
		&returns,
	)

	return returns
}

// Returns true if the construct was created by CDK, and false otherwise.
// Experimental.
func PySparkEtlJob_IsOwnedResource(construct constructs.IConstruct) *bool {
	_init_.Initialize()

	if err := validatePySparkEtlJob_IsOwnedResourceParameters(construct); err != nil {
		panic(err)
	}
	var returns *bool

	_jsii_.StaticInvoke(
		"@aws-cdk/aws-glue-alpha.PySparkEtlJob",
		"isOwnedResource",
		[]interface{}{construct},
		&returns,
	)

	return returns
}

// Check whether the given construct is a Resource.
// Experimental.
func PySparkEtlJob_IsResource(construct constructs.IConstruct) *bool {
	_init_.Initialize()

	if err := validatePySparkEtlJob_IsResourceParameters(construct); err != nil {
		panic(err)
	}
	var returns *bool

	_jsii_.StaticInvoke(
		"@aws-cdk/aws-glue-alpha.PySparkEtlJob",
		"isResource",
		[]interface{}{construct},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) ApplyRemovalPolicy(policy awscdk.RemovalPolicy) {
	if err := p.validateApplyRemovalPolicyParameters(policy); err != nil {
		panic(err)
	}
	_jsii_.InvokeVoid(
		p,
		"applyRemovalPolicy",
		[]interface{}{policy},
	)
}

func (p *jsiiProxy_PySparkEtlJob) BuildJobArn(scope constructs.Construct, jobName *string) *string {
	if err := p.validateBuildJobArnParameters(scope, jobName); err != nil {
		panic(err)
	}
	var returns *string

	_jsii_.Invoke(
		p,
		"buildJobArn",
		[]interface{}{scope, jobName},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) CheckNoReservedArgs(defaultArguments *map[string]*string) *map[string]*string {
	var returns *map[string]*string

	_jsii_.Invoke(
		p,
		"checkNoReservedArgs",
		[]interface{}{defaultArguments},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) CodeS3ObjectUrl(code Code) *string {
	if err := p.validateCodeS3ObjectUrlParameters(code); err != nil {
		panic(err)
	}
	var returns *string

	_jsii_.Invoke(
		p,
		"codeS3ObjectUrl",
		[]interface{}{code},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) GeneratePhysicalName() *string {
	var returns *string

	_jsii_.Invoke(
		p,
		"generatePhysicalName",
		nil, // no parameters
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) GetResourceArnAttribute(arnAttr *string, arnComponents *awscdk.ArnComponents) *string {
	if err := p.validateGetResourceArnAttributeParameters(arnAttr, arnComponents); err != nil {
		panic(err)
	}
	var returns *string

	_jsii_.Invoke(
		p,
		"getResourceArnAttribute",
		[]interface{}{arnAttr, arnComponents},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) GetResourceNameAttribute(nameAttr *string) *string {
	if err := p.validateGetResourceNameAttributeParameters(nameAttr); err != nil {
		panic(err)
	}
	var returns *string

	_jsii_.Invoke(
		p,
		"getResourceNameAttribute",
		[]interface{}{nameAttr},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) Metric(metricName *string, type_ MetricType, props *awscloudwatch.MetricOptions) awscloudwatch.Metric {
	if err := p.validateMetricParameters(metricName, type_, props); err != nil {
		panic(err)
	}
	var returns awscloudwatch.Metric

	_jsii_.Invoke(
		p,
		"metric",
		[]interface{}{metricName, type_, props},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) MetricFailure(props *awscloudwatch.MetricOptions) awscloudwatch.Metric {
	if err := p.validateMetricFailureParameters(props); err != nil {
		panic(err)
	}
	var returns awscloudwatch.Metric

	_jsii_.Invoke(
		p,
		"metricFailure",
		[]interface{}{props},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) MetricSuccess(props *awscloudwatch.MetricOptions) awscloudwatch.Metric {
	if err := p.validateMetricSuccessParameters(props); err != nil {
		panic(err)
	}
	var returns awscloudwatch.Metric

	_jsii_.Invoke(
		p,
		"metricSuccess",
		[]interface{}{props},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) MetricTimeout(props *awscloudwatch.MetricOptions) awscloudwatch.Metric {
	if err := p.validateMetricTimeoutParameters(props); err != nil {
		panic(err)
	}
	var returns awscloudwatch.Metric

	_jsii_.Invoke(
		p,
		"metricTimeout",
		[]interface{}{props},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) NonExecutableCommonArguments(props *SparkJobProps) *map[string]*string {
	if err := p.validateNonExecutableCommonArgumentsParameters(props); err != nil {
		panic(err)
	}
	var returns *map[string]*string

	_jsii_.Invoke(
		p,
		"nonExecutableCommonArguments",
		[]interface{}{props},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) OnEvent(id *string, options *awsevents.OnEventOptions) awsevents.Rule {
	if err := p.validateOnEventParameters(id, options); err != nil {
		panic(err)
	}
	var returns awsevents.Rule

	_jsii_.Invoke(
		p,
		"onEvent",
		[]interface{}{id, options},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) OnFailure(id *string, options *awsevents.OnEventOptions) awsevents.Rule {
	if err := p.validateOnFailureParameters(id, options); err != nil {
		panic(err)
	}
	var returns awsevents.Rule

	_jsii_.Invoke(
		p,
		"onFailure",
		[]interface{}{id, options},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) OnStateChange(id *string, jobState JobState, options *awsevents.OnEventOptions) awsevents.Rule {
	if err := p.validateOnStateChangeParameters(id, jobState, options); err != nil {
		panic(err)
	}
	var returns awsevents.Rule

	_jsii_.Invoke(
		p,
		"onStateChange",
		[]interface{}{id, jobState, options},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) OnSuccess(id *string, options *awsevents.OnEventOptions) awsevents.Rule {
	if err := p.validateOnSuccessParameters(id, options); err != nil {
		panic(err)
	}
	var returns awsevents.Rule

	_jsii_.Invoke(
		p,
		"onSuccess",
		[]interface{}{id, options},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) OnTimeout(id *string, options *awsevents.OnEventOptions) awsevents.Rule {
	if err := p.validateOnTimeoutParameters(id, options); err != nil {
		panic(err)
	}
	var returns awsevents.Rule

	_jsii_.Invoke(
		p,
		"onTimeout",
		[]interface{}{id, options},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) SetupContinuousLogging(role awsiam.IRole, props *ContinuousLoggingProps) interface{} {
	if err := p.validateSetupContinuousLoggingParameters(role, props); err != nil {
		panic(err)
	}
	var returns interface{}

	_jsii_.Invoke(
		p,
		"setupContinuousLogging",
		[]interface{}{role, props},
		&returns,
	)

	return returns
}

func (p *jsiiProxy_PySparkEtlJob) SetupExtraCodeArguments(args *map[string]*string, props *SparkExtraCodeProps) {
	if err := p.validateSetupExtraCodeArgumentsParameters(args, props); err != nil {
		panic(err)
	}
	_jsii_.InvokeVoid(
		p,
		"setupExtraCodeArguments",
		[]interface{}{args, props},
	)
}

func (p *jsiiProxy_PySparkEtlJob) ToString() *string {
	var returns *string

	_jsii_.Invoke(
		p,
		"toString",
		nil, // no parameters
		&returns,
	)

	return returns
}

